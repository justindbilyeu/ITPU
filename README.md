# Information-Theoretic Processing Unit (ITPU)

**Accelerate entropy, mutual information (MI), and k-NNâ€“based estimatorsâ€”starting in software, designed for hardware.**  
Apache-2.0 â€¢ Pre-alpha

---

## What is ITPU (in plain English)

Modern chips are great at matrix math (good for neural nets) but bad at measuring information itself. Many real problemsâ€”BCI/neuroscience, medical image registration, causal discoveryâ€”need **entropy/MI** and **k-NN statistics** fast and in streaming form.  
**ITPU** is a coprocessor concept and an SDK: weâ€™re shipping a **software SDK now** (same API youâ€™ll use on a future FPGA/ASIC), so you can profile information flow today and drop in hardware later without changing code.

---

## Status: **Software-first pivot (Sept 2025)**

- âœ… **Working now:** histogram-based MI (`method="hist"`), sliding-window/streaming helpers
- ðŸ§ª **In progress:** KSG MI (`method="ksg"`, k-NN estimator), benchmarking suite, EEG demo
- ðŸ§­ **Road to hardware:** weâ€™ll validate kernels + users in software, then lift the exact API onto an FPGA pathfinder

---
'''
## Quickstart (local, pre-alpha)

```bash
# 1) Clone and enter the repo root (folder that contains README.md and the itpu/ directory)
git clone https://github.com/justindbilyeu/ITPU
cd ITPU

# 2) (Recommended) Create a virtual env
python -m venv .venv
# Mac/Linux:
source .venv/bin/activate
# Windows (PowerShell):
# .venv\Scripts\Activate.ps1

# 3) Minimal deps for the software path
pip install numpy scipy

# 4) Run the smoke test
python scripts/smoke_test.py

You should see non-zero MI printed and a count of sliding-window results.

â¸»

Minimal API
- Histogram MI: fast, discrete approximation
- KSG MI: continuous estimator (Kraskovâ€“StÃ¶gbauerâ€“Grassberger, variant I)
  * Default metric = chebyshev (p = âˆž norm)
  * Returns MI in nats
from itpu.sdk import ITPU
from itpu.utils.windowed import windowed_mi
import numpy as np

itpu = ITPU(device="software")  # same API will target FPGA later

# Example: point MI (histogram method)
x = np.random.randn(50_000)
y = 0.6*x + 0.4*np.random.randn(50_000)
mi = itpu.mutual_info(x, y, method="hist", bins=64)  # returns MI in nats

# Sliding-window MI (hist)
starts, mi_vals = windowed_mi(x, y, window_size=2000, hop_size=400, bins=64)

KSG (k-NN) estimator is being wired up; youâ€™ll call it with method="ksg", k=5 once merged.

â¸»

Why software-first?
	â€¢	Faster proof, lower risk. We validate accuracy, speed, and UX now.
	â€¢	Same API later. When the FPGA card lands, you flip device="software" â†’ device="fpga"; no code rewrite.
	â€¢	Streaming is the wedge. Most MI libraries are batch-only; weâ€™re prioritizing sliding windows + real-time.

â¸»

Benchmarks (tracking)

Weâ€™re adding benchmarks/ to compare ITPU software vs. SciPy/scikit-learn/JIDT on identical data:
	â€¢	Throughput for histogram MI
	â€¢	Latency for sliding windows
	â€¢	Accuracy vs. known MI for synthetic distributions

Early goalposts: â‰¥2â€“5Ã— faster histogram MI on common sizes and first-class streaming others lack.

â¸»

Roadmap (R1 â†’ R3 software, R4 â†’ R5 hardware)
	â€¢	R1 (now): histogram MI + sliding windows, smoke tests, clean docs
	â€¢	R2 (next): KSG MI (ksg_mi_estimate), comprehensive benchmarks, EEG streaming demo
	â€¢	R3: convenience APIs (batched MI matrices, masks, categorical MI), optional CuPy acceleration
	â€¢	R4: FPGA pathfinder spec + sizing; partner pilots (BCI first)
	â€¢	R5: ASIC decision (only after proven demand + perf)

â¸»

Example demos
	â€¢	scripts/smoke_test.py â€“ quick sanity check
	â€¢	examples/eeg_streaming_demo.py â€“ streaming MI on EEG (uses local CSV or synthetic fallback)
	â€¢	benchmarks/compare_baselines.py â€“ apples-to-apples against popular libs (coming online)

â¸»

FAQ

Why not just use a GPU?
GPUs crush dense matrices; MI/k-NN are irregular and memory-bound. We optimize dataflow for histograms and neighbor counts, and offer true streamingâ€”then port exactly that to hardware.

Do I need special hardware?
No. Today is pure Python/NumPy/SciPy. The same code will target an FPGA card later.

Units?
MI is reported in nats (divide by np.log(2) for bits).

â¸»

Contributing

Issues and PRs welcome! High-leverage areas:
	â€¢	KSG estimator internals and tests (itpu/kernels_sw/ksg.py)
	â€¢	Streaming/windowing utilities
	â€¢	Benchmarks and real-world datasets (EEG/BCI preferred for now)

Dev tips:

# From repo root
pip install -r requirements-dev.txt   # (if present; otherwise numpy/scipy/matplotlib)
pytest -q                             # test suite (coming online)


â¸»

License

Apache-2.0. See LICENSE.
