{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# WS1 Pilot Study: Inter-Rater Reliability\n", "\n", "This notebook demonstrates how to compute **Cohen's \u03ba** (for categorical ratings) and **ICC** (for continuous scores) using the `phenom_tools.py` helper functions."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "from phenom_tools import compute_kappa, compute_icc, reliability_report\n", "\n", "# Example categorical ratings from two raters\n", "rater1 = [\"lattice\", \"spiral\", \"tunnel\", \"spiral\"]\n", "rater2 = [\"lattice\", \"spiral\", \"tunnel\", \"lattice\"]\n", "\n", "kappa = compute_kappa(rater1, rater2)\n", "print(\"Cohen\u2019s \u03ba:\", kappa)\n", "\n", "# Example continuous ratings (0\u201310 scales)\n", "df = pd.DataFrame({\n", "    \"rater1\": [7, 5, 9, 6],\n", "    \"rater2\": [8, 6, 8, 5]\n", "})\n", "\n", "icc = compute_icc(df)\n", "print(\"ICC:\", icc)\n", "\n", "# Full reliability report\n", "report = reliability_report(rater1, rater2, df)\n", "print(\"\\nReliability Report:\")\n", "print(report)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"file_extension": ".py", "mimetype": "text/x-python", "name": "python", "pygments_lexer": "ipython3", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 5}